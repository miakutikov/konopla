"""
publisher.py ‚Äî –°—Ç–≤–æ—Ä—é—î Hugo markdown —Ñ–∞–π–ª–∏ –∑ –ø–µ—Ä–µ–ø–∏—Å–∞–Ω–∏—Ö –Ω–æ–≤–∏–Ω
"""

import os
import re
from datetime import datetime, timezone


def fix_double_utf8(text):
    """
    Fix double-encoded UTF-8 text.

    When UTF-8 bytes are mistakenly interpreted as Latin-1 and then
    re-encoded to UTF-8, we get sequences like c3 90 c2 92 instead of d0 92.
    This function detects and reverses that process.

    Safe to call on already-correct text ‚Äî returns it unchanged.
    """
    if not isinstance(text, str):
        return text
    try:
        # Try to encode as Latin-1: this only succeeds if every character
        # is in the 0x00-0xFF range (which is the symptom of double-encoding).
        raw = text.encode('latin-1')
        # Now decode those bytes as UTF-8 to recover the original text.
        fixed = raw.decode('utf-8')
        return fixed
    except (UnicodeEncodeError, UnicodeDecodeError):
        # Not double-encoded ‚Äî return as-is
        return text


def fix_article_encoding(article_data):
    """Apply fix_double_utf8 to all text fields in article data."""
    fixed = dict(article_data)
    for key in ('title', 'summary', 'content', 'category'):
        if key in fixed and isinstance(fixed[key], str):
            fixed[key] = fix_double_utf8(fixed[key])
    if 'tags' in fixed and isinstance(fixed['tags'], list):
        fixed['tags'] = [fix_double_utf8(t) if isinstance(t, str) else t for t in fixed['tags']]
    return fixed


def slugify(text):
    """–°—Ç–≤–æ—Ä—é—î URL-friendly slug –∑ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç—É."""
    # Transliteration map for Ukrainian
    translit = {
        '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': 'h', '“ë': 'g', '–¥': 'd', '–µ': 'e',
        '—î': 'ye', '–∂': 'zh', '–∑': 'z', '–∏': 'y', '—ñ': 'i', '—ó': 'yi', '–π': 'y',
        '–∫': 'k', '–ª': 'l', '–º': 'm', '–Ω': 'n', '–æ': 'o', '–ø': 'p', '—Ä': 'r',
        '—Å': 's', '—Ç': 't', '—É': 'u', '—Ñ': 'f', '—Ö': 'kh', '—Ü': 'ts', '—á': 'ch',
        '—à': 'sh', '—â': 'shch', '—å': '', '—é': 'yu', '—è': 'ya', '—ä': '', '—ã': 'y',
        '—ç': 'e',
    }
    
    text = text.lower().strip()
    result = []
    for char in text:
        if char in translit:
            result.append(translit[char])
        elif char.isascii() and (char.isalnum() or char == '-'):
            result.append(char)
        elif char in (' ', '_', '.'):
            result.append('-')
    
    slug = '-'.join(filter(None, ''.join(result).split('-')))
    return slug[:80]  # Limit length


def create_article_file(article_data, source_url, source_name, image_data=None, content_dir="content/news", draft=False):
    """
    –°—Ç–≤–æ—Ä—é—î Hugo markdown —Ñ–∞–π–ª –¥–ª—è —Å—Ç–∞—Ç—Ç—ñ.

    article_data: dict from Gemini (title, summary, content, category, tags)
    source_url: URL –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ—ó —Å—Ç–∞—Ç—Ç—ñ
    source_name: –Ω–∞–∑–≤–∞ –¥–∂–µ—Ä–µ–ª–∞
    image_data: dict from Unsplash (url, author, author_url, unsplash_url) or None
    content_dir: –ø–∞–ø–∫–∞ –¥–ª—è –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è
    draft: —è–∫—â–æ True, —Å—Ç–∞—Ç—Ç—è —Å—Ç–≤–æ—Ä—é—î—Ç—å—Å—è —è–∫ —á–µ—Ä–Ω–µ—Ç–∫–∞ (draft: true)
    
    –ü–æ–≤–µ—Ä—Ç–∞—î —à–ª—è—Ö –¥–æ —Å—Ç–≤–æ—Ä–µ–Ω–æ–≥–æ —Ñ–∞–π–ª—É –∞–±–æ None.
    """
    try:
        # Fix potential double-encoded UTF-8 from pipeline
        article_data = fix_article_encoding(article_data)

        now = datetime.now(timezone.utc)
        date_str = now.strftime("%Y-%m-%dT%H:%M:%S+00:00")
        date_prefix = now.strftime("%Y%m%d-%H%M")

        title = article_data["title"]
        summary = article_data["summary"]
        content = article_data["content"]
        category = article_data.get("category", "—ñ–Ω—à–µ")
        tags = article_data.get("tags", [])
        
        slug = slugify(title)
        filename = f"{date_prefix}-{slug}.md"
        filepath = os.path.join(content_dir, filename)
        
        # Build front matter
        tags_str = ", ".join(f'"{tag}"' for tag in tags[:5])
        
        # Image lines
        image_line = ""
        image_credit = ""
        if image_data:
            image_line = f'image: "{image_data["url"]}"'
            img_source = image_data.get("source", "unsplash")
            if img_source == "gemini":
                image_credit = (
                    f'image_source: "AI Generated"'
                )
            else:
                image_credit = (
                    f'image_author: "{image_data.get("author", "")}"'
                    f'\nimage_author_url: "{image_data.get("author_url", "")}"'
                    f'\nimage_source: "Unsplash"'
                    f'\nimage_source_url: "{image_data.get("unsplash_url", "")}"'
                )
        
        # Build front matter lines
        fm_lines = [
            "---",
            f'title: "{title.replace(chr(34), chr(39))}"',
            f"date: {date_str}",
            f'summary: "{summary.replace(chr(34), chr(39))}"',
            f'categories: ["{category}"]',
            f"tags: [{tags_str}]",
            f'source: "{source_name.replace(chr(34), chr(39))}"',
            f'source_url: "{source_url}"',
        ]
        if image_line:
            fm_lines.append(image_line)
        if image_credit:
            fm_lines.append(image_credit)
        fm_lines.append(f"draft: {'true' if draft else 'false'}")
        fm_lines.append("---")
        fm_lines.append("")
        fm_lines.append(content)
        fm_lines.append("")

        front_matter = "\n".join(fm_lines)
        
        # Add image credit at the bottom if available
        if image_data:
            from images import format_image_credit_md
            credit = format_image_credit_md(image_data)
            if credit:
                front_matter += f"\n\n---\n{credit}\n"
        
        os.makedirs(content_dir, exist_ok=True)
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(front_matter)
        
        print(f"[OK] Created: {filepath}")
        return filepath
        
    except Exception as e:
        print(f"[ERROR] Failed to create article file: {e}")
        return None


def create_telegram_message(article_data, site_url="https://konopla.ua"):
    """
    –§–æ—Ä–º—É—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –¥–ª—è Telegram-–∫–∞–Ω–∞–ª—É.
    –ü–æ–≤–µ—Ä—Ç–∞—î —Ç–µ–∫—Å—Ç –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è.
    """
    article_data = fix_article_encoding(article_data)
    title = article_data["title"]
    summary = article_data["summary"]
    category = article_data.get("category", "")
    slug = slugify(title)
    
    now = datetime.now(timezone.utc)
    date_prefix = now.strftime("%Y%m%d-%H%M")
    
    article_url = f"{site_url}/news/{date_prefix}-{slug}/"
    
    # Emoji per category
    emoji_map = {
        "—Ç–µ–∫—Å—Ç–∏–ª—å": "üßµ",
        "–±—É–¥—ñ–≤–Ω–∏—Ü—Ç–≤–æ": "üèóÔ∏è",
        "–∞–≥—Ä–æ": "üå±",
        "–±—ñ–æ–ø–ª–∞—Å—Ç–∏–∫": "‚ôªÔ∏è",
        "–∞–≤—Ç–æ–ø—Ä–æ–º": "üöó",
        "—Ö–∞—Ä—á–æ–≤–∞": "ü•ó",
        "–µ–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞": "‚ö°",
        "–∫–æ—Å–º–µ—Ç–∏–∫–∞": "‚ú®",
        "–∑–∞–∫–æ–Ω–æ–¥–∞–≤—Å—Ç–≤–æ": "üìã",
        "–Ω–∞—É–∫–∞": "üî¨",
        "—ñ–Ω—à–µ": "üì∞",
    }
    emoji = emoji_map.get(category, "üì∞")
    
    message = f"""{emoji} <b>{title}</b>

{summary}

<a href="{article_url}">–ß–∏—Ç–∞—Ç–∏ –ø–æ–≤–Ω—ñ—Å—Ç—é ‚Üí</a>"""
    
    return message


if __name__ == "__main__":
    # Test
    test_data = {
        "title": "–ù—ñ–º–µ—á—á–∏–Ω–∞ –∑–∞–ø—É—Å–∫–∞—î –∑–∞–≤–æ–¥ –∑ –≤–∏—Ä–æ–±–Ω–∏—Ü—Ç–≤–∞ –∫–æ–Ω–æ–ø–ª—è–Ω–æ–≥–æ –±–µ—Ç–æ–Ω—É",
        "summary": "–ù–æ–≤–∏–π –∑–∞–≤–æ–¥ —É –ë–∞–≤–∞—Ä—ñ—ó –≤–∏—Ä–æ–±–ª—è—î –±–ª–æ–∫–∏ –∑ –∫–æ–Ω–æ–ø–ª—è–Ω–æ–≥–æ –±–µ—Ç–æ–Ω—É –¥–ª—è –∂–∏—Ç–ª–æ–≤–æ–≥–æ –±—É–¥—ñ–≤–Ω–∏—Ü—Ç–≤–∞.",
        "content": "–¢–µ—Å—Ç–æ–≤–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å—Ç–∞—Ç—Ç—ñ.\n\n–î—Ä—É–≥–∏–π –∞–±–∑–∞—Ü.",
        "category": "–±—É–¥—ñ–≤–Ω–∏—Ü—Ç–≤–æ",
        "tags": ["–∫–æ–Ω–æ–ø–ª—è–Ω–∏–π –±–µ—Ç–æ–Ω", "–Ω—ñ–º–µ—á—á–∏–Ω–∞", "–±—É–¥—ñ–≤–Ω–∏—Ü—Ç–≤–æ"]
    }
    
    filepath = create_article_file(test_data, "https://example.com", "Test Source")
    print(f"Created: {filepath}")
    
    msg = create_telegram_message(test_data)
    print(f"\nTelegram message:\n{msg}")
